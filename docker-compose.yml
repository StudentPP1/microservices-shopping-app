version: '4'
services:
  keycloak-mysql: # database for keycloak -> mysql
    container_name: keycloak-mysql
    image: mysql:8
    volumes:
      - ./volume-data/mysql_keycloak_data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: keycloak
      MYSQL_USER: keycloak
      MYSQL_PASSWORD: password

  keycloak:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:24.0.1
    command: [ "start-dev", "--import-realm" ] # start keycloak in dev env & import realms
    environment: # connect to mysql db
      DB_VENDOR: MYSQL
      DB_ADDR: keycloak-mysql
      DB_DATABASE: keycloak
      DB_USER: keycloak
      DB_PASSWORD: password
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports: # from docker container keycloak access by 8181
      - "8181:8080"
    volumes:
      - ./docker/keycloak/realms/:/opt/keycloak/data/import/
    depends_on:
      - keycloak-mysql

  loki: # log appender collects all logs from app in one place
    image: grafana/loki:main
    command: [ "-config.file=/etc/loki/local-config.yaml" ]
    ports:
      - "3100:3100"

  prometheus: # scrapes all info from app and calculate metrics
    image: prom/prometheus:v2.46.0
    command:
      - --enable-feature=exemplar-storage
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - '9090:9090'

  tempo: # collect all request and queries tracing
    image: grafana/tempo:2.2.2
    command: [ '-config.file=/etc/tempo.yaml' ]
    volumes:
      - ./docker/tempo/tempo.yml:/etc/tempo.yaml:ro
      - ./docker/tempo/tempo-data:/tmp/tempo
    ports:
      - '3110:3100' # Tempo
      - '9411:9411' # zipkin

  grafana: # aggregate all previous staff and show to us
    image: grafana/grafana:10.1.0
    volumes:
      - ./docker/grafana:/etc/grafana/provisioning/datasources:ro
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    ports:
      - '3000:3000'

  zookeeper: # оркестрирование разных кластеров кафки
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.5.0
    container_name: broker
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1 # айдишник брокера
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181' # подключение к zookeeper
      # протокол безопасности (шифрование)
      # в нашем случае просто текст
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # слушатели подключений к кафке
      # для других контейнеров с порта 29092, для локальной машины - 9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      # создаст 1 брокер для копирования информации об
      # прочитанных данных (consumer group)
      # до какого места дочитали в топиках (offset) и тд
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  schema-registry: # allow not duplicate message class type in two services
    image: confluentinc/cp-schema-registry:7.5.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8085:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092' # соединение с брокером
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081 # expose listen port

  kafka-ui: # юзер интерфейс для просмотра информации внутри брокера
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8086:8080" # в докер-контейнере будет 8080
    depends_on:
      - broker
      - schema-registry
    environment:
      KAFKA_CLUSTERS_NAME: local # используем локальный кластер
      KAFKA_CLUSTERS_BOOTSTRAPSERVERS: broker:29092 # подключаемся к брокеру через контейнер
      KAFKA_CLUSTERS_SCHEMAREGISTRY: http://schema-registry:8081
      DYNAMIC_CONFIG_ENABLED: 'true' # зависит от образа юзер интерфейса

  order-service-db:
    image: postgres:latest
    container_name: order-service-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: order_service
    ports:
      - "5432:5432"
    volumes:
      - ./order-service-db:/var/lib/postgres
      # ./docker/mysql/init.sql => файл на локалій машині
      # /docker-entrypoint-initdb.d => копіюємо в папку, яку контейнер перевіряє при запуску і запускає звідси файли
      # - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql

  inventory-service-db:
    image: postgres:latest
    container_name: inventory-service-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: inventory_service
    ports:
      - "5442:5432" # поменяли внутренний порт, что бы избежать конфликта с order-service-db
    volumes:
      - ./inventory-service-db:/var/lib/postgres
      # ! ./inventory-service-db => створиться папка на локалій машині, там де заходиться docker-compose
      # ! /var/lib/postgres => папка всередині контейнера
      # ! Щоб усі дані бази зберігалися на хості, навіть якщо контейнер буде видалено або перезапущено.

  product-service-db:
    image: mongo:7.0.5
    container_name: product-service-db
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: password
      MONGO_INITDB_DATABASE: product-service
    volumes:
      - ./product-service-db:/data/db # store all files and data for mongodb